{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n"
      ],
      "metadata": {
        "id": "qHfkshedSRyH"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython import get_ipython\n",
        "from IPython.display import display"
      ],
      "metadata": {
        "id": "bvDnqyfSMn70"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuSSeoFwlz-Y",
        "outputId": "a5d4d287-d9ce-448d-df59-a7d0b444cbf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'fewshot-face-translation-GAN' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "# Clone dev branch for the latest model\n",
        "!git clone -b dev --recursive https://github.com/shaoanlu/fewshot-face-translation-GAN.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bfGNntU5LfeX"
      },
      "outputs": [],
      "source": [
        "# There are import errors under keras == 2.2.5\n",
        "!pip install --upgrade tensorflow keras --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Iwycx0MyUXot"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd fewshot-face-translation-GAN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kizuaZ1nOXBn",
        "outputId": "76054c32-e919-49d9-e9af-7890510606fc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fewshot-face-translation-GAN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUDjTRuiLfeZ",
        "outputId": "6b397b78-1c08-45be-d910-6bfc9e37ce20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ThyUhXkVY5WJIRbik_Jpx9vOqEQ4jEZw\n",
            "To: /content/fewshot-face-translation-GAN/encoder.h5\n",
            "100% 6.26M/6.26M [00:00<00:00, 75.3MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1cVkPjTxqQXo0pyLQHw_Yhngc4GO6KB5Q\n",
            "From (redirected): https://drive.google.com/uc?id=1cVkPjTxqQXo0pyLQHw_Yhngc4GO6KB5Q&confirm=t&uuid=1d03f154-dfe0-462e-bb6b-79fa353db3f0\n",
            "To: /content/fewshot-face-translation-GAN/decoder.h5\n",
            "100% 126M/126M [00:01<00:00, 67.2MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Download pre-trined weights\n",
        "!gdown https://drive.google.com/uc?id=1ThyUhXkVY5WJIRbik_Jpx9vOqEQ4jEZw\n",
        "!gdown https://drive.google.com/uc?id=1cVkPjTxqQXo0pyLQHw_Yhngc4GO6KB5Q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9b2N8INnm8P",
        "outputId": "55520ed4-1852-4c5a-ff69-1f9e22b7b26e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘weights’: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir weights\n",
        "!mv decoder.h5 weights/decoder.h5\n",
        "!mv encoder.h5 weights/encoder.h5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcdF2i9umQGk",
        "outputId": "c010a4d3-3cef-41ad-a4c1-78c6c5c628c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "colab_demo.ipynb    fewshot-face-translation-GAN  preprocess.py  utils\n",
            "configs\t\t    images\t\t\t  __pycache__\t weights\n",
            "data\t\t    models.py\t\t\t  README.md\n",
            "face_toolbox_keras  networks\t\t\t  train.py\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!grep -rn \"get_default_graph\" /content/fewshot-face-translation-GAN/\n"
      ],
      "metadata": {
        "id": "ODIrwI5EUWon"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dc7-w7eLfeb"
      },
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tj4uhc8dLfeb",
        "outputId": "37733c7a-384a-40db-baf3-3fdbe17b5701"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dir_weights': './weights',\n",
              " 'identity_extractor': 'inceptionresnetv1',\n",
              " 'input_size': 224,\n",
              " 'latent_dim': 512,\n",
              " 'separate_adain': True,\n",
              " 'additional_emb': True,\n",
              " 'use_nwg': False,\n",
              " 'nc_in': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "from utils.config_loader import load_yaml\n",
        "config = load_yaml(\"configs/config_inference.yaml\"); config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htzgMCcYlz_G"
      },
      "source": [
        "## Load GAN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "PDCd3QM_lz_J"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Navigate to the models.py file in the cloned repository and modify it.\n",
        "# Replace the line importing Beta from tensorflow.contrib\n",
        "!sed -i \"s/from tensorflow.contrib.distributions import Beta/from tensorflow.compat.v1.distributions import Beta/\" /content/fewshot-face-translation-GAN/fewshot-face-translation-GAN/models.py"
      ],
      "metadata": {
        "id": "1_0KRNr0M9js"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/fewshot-face-translation-GAN/models.py\"\n",
        "\n",
        "with open(file_path, \"r\") as file:\n",
        "    code = file.read()\n",
        "\n",
        "# Remove old contrib import\n",
        "code = code.replace(\"from tensorflow.contrib.distributions import Beta\",\n",
        "                    \"import tensorflow_probability as tfp\\nBeta = tfp.distributions.Beta\")\n",
        "\n",
        "with open(file_path, \"w\") as file:\n",
        "    file.write(code)\n",
        "\n",
        "print(\"Updated import for Beta distribution using TensorFlow Probability.\")\n"
      ],
      "metadata": {
        "id": "1L_Lt6iObuOT",
        "outputId": "d9254273-2b25-4ae0-fa06-9f29f418b68f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated import for Beta distribution using TensorFlow Probability.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/fewshot-face-translation-GAN/networks/nn_blocks.py\"\n",
        "\n",
        "with open(file_path, \"r\") as f:\n",
        "    code = f.read()\n",
        "\n",
        "# Fix invalid import\n",
        "code = code.replace(\n",
        "    \"from keras.layers.advanced_activations import LeakyReLU\",\n",
        "    \"from keras.layers import LeakyReLU\"\n",
        ")\n",
        "\n",
        "with open(file_path, \"w\") as f:\n",
        "    f.write(code)\n",
        "\n",
        "print(\"Fixed LeakyReLU import in nn_blocks.py\")\n"
      ],
      "metadata": {
        "id": "0OFdAeJSb-f9",
        "outputId": "6abecaca-8e49-4732-d206-75dfd94cf0d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fixed LeakyReLU import in nn_blocks.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/fewshot-face-translation-GAN/networks/instance_normalization.py\"\n",
        "\n",
        "with open(file_path, \"r\") as f:\n",
        "    code = f.read()\n",
        "\n",
        "# Fix Layer + InputSpec import\n",
        "code = code.replace(\n",
        "    \"from keras.engine import Layer, InputSpec\",\n",
        "    \"from tensorflow.keras.layers import Layer, InputSpec\"\n",
        ")\n",
        "\n",
        "# Ensure all other keras.* are tensorflow.keras.*\n",
        "code = code.replace(\"from keras.\", \"from tensorflow.keras.\")\n",
        "code = code.replace(\"import keras.\", \"import tensorflow.keras.\")\n",
        "\n",
        "with open(file_path, \"w\") as f:\n",
        "    f.write(code)\n",
        "\n",
        "print(\"Fixed imports in instance_normalization.py\")\n"
      ],
      "metadata": {
        "id": "fesDNesBcJkn",
        "outputId": "317680f5-0c83-45ac-e013-9578b6f4170e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fixed imports in instance_normalization.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find /content/fewshot-face-translation-GAN -type f -name \"*.py\" -exec sed -i 's/tf\\.get_default_graph()/tf.compat.v1.get_default_graph()/g' {} \\;\n",
        "\n",
        "print(\"Replaced tf.get_default_graph() with tf.compat.v1.get_default_graph()\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwO5oblYQE_J",
        "outputId": "1fff9f09-3927-4c3b-c6d8-fad0b6a93069"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Replaced tf.get_default_graph() with tf.compat.v1.get_default_graph()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/fewshot-face-translation-GAN/networks/instance_normalization.py\"\n",
        "\n",
        "with open(file_path, \"r\") as f:\n",
        "    code = f.read()\n",
        "\n",
        "# Fix Layer + InputSpec import\n",
        "code = code.replace(\n",
        "    \"from keras.engine import Layer, InputSpec\",\n",
        "    \"from tensorflow.keras.layers import Layer, InputSpec\"\n",
        ")\n",
        "\n",
        "# Fix the import path for get_custom_objects\n",
        "code = code.replace(\n",
        "    \"from tensorflow.keras.utils.generic_utils import get_custom_objects\",\n",
        "    \"from tensorflow.keras.utils import get_custom_objects\"\n",
        ")\n",
        "\n",
        "\n",
        "# Ensure all other keras.* are tensorflow.keras.*\n",
        "code = code.replace(\"from keras.\", \"from tensorflow.keras.\")\n",
        "code = code.replace(\"import keras.\", \"import tensorflow.keras.\")\n",
        "\n",
        "with open(file_path, \"w\") as f:\n",
        "    f.write(code)\n",
        "\n",
        "print(\"Fixed imports in instance_normalization.py\")"
      ],
      "metadata": {
        "id": "LOx9n_v0c5z6",
        "outputId": "102a5d09-fa39-4135-ca68-e607aae137c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fixed imports in instance_normalization.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/fewshot-face-translation-GAN/networks/discriminator.py\"\n",
        "\n",
        "with open(file_path, \"r\") as f:\n",
        "    code = f.read()\n",
        "\n",
        "# Fix invalid import for LeakyReLU\n",
        "code = code.replace(\n",
        "    \"from keras.layers.advanced_activations import LeakyReLU\",\n",
        "    \"from keras.layers import LeakyReLU\"\n",
        ")\n",
        "\n",
        "with open(file_path, \"w\") as f:\n",
        "    f.write(code)\n",
        "\n",
        "print(\"Fixed LeakyReLU import in discriminator.py\")"
      ],
      "metadata": {
        "id": "qdBfTyLsdDZO",
        "outputId": "29a17158-c2dc-4937-e40a-82bd2eb17282",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fixed LeakyReLU import in discriminator.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "SByaoidilz_O",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from models import FaceTranslationGANInferenceModel"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EEwYzdAadE2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "id": "LRheogi-lz_U",
        "outputId": "f5e8f562-e31a-43ac-bbdc-a840ee1ea725",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "Error building networks.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/content/fewshot-face-translation-GAN/models.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/fewshot-face-translation-GAN/models.py\u001b[0m in \u001b[0;36mbuild_encoder\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnc_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/fewshot-face-translation-GAN/networks/generator.py\u001b[0m in \u001b[0;36mencoder\u001b[0;34m(nc_in, input_size)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp_segm_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mconv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/fewshot-face-translation-GAN/networks/nn_blocks.py\u001b[0m in \u001b[0;36mconv_block\u001b[0;34m(input_tensor, f, use_norm, k, strides)\u001b[0m\n\u001b[1;32m     45\u001b[0m                kernel_initializer=conv_init, use_bias=(not use_norm))(x)\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_norm\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/fewshot-face-translation-GAN/networks/nn_blocks.py\u001b[0m in \u001b[0;36mnormalization\u001b[0;34m(inp, norm, group)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mnorm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'instancenorm'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInstanceNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0;31m#elif norm == \"SPADE_norm\":\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/fewshot-face-translation-GAN/networks/instance_normalization.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: Exception encountered when calling InstanceNormalization.call().\n\n\u001b[1mCould not automatically infer the output shape / dtype of 'instance_normalization_2' (of type InstanceNormalization). Either the `InstanceNormalization.call()` method is incorrect, or you need to implement the `InstanceNormalization.compute_output_spec() / compute_output_shape()` method. Error encountered:\n\nmodule 'keras.backend' has no attribute 'int_shape'\u001b[0m\n\nArguments received by InstanceNormalization.call():\n  • args=('<KerasTensor shape=(None, 112, 112, 64), dtype=float32, sparse=False, ragged=False, name=keras_tensor_23>',)\n  • kwargs=<class 'inspect._empty'>",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-31-212219274.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFaceTranslationGANInferenceModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/fewshot-face-translation-GAN/models.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error building networks.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdir_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dir_weights\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdir_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: Error building networks."
          ]
        }
      ],
      "source": [
        "model = FaceTranslationGANInferenceModel(config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CpyAOeYXlz_w"
      },
      "outputs": [],
      "source": [
        "from face_toolbox_keras.models.verifier.face_verifier import FaceVerifier\n",
        "fv = FaceVerifier(classes=512)\n",
        "\n",
        "from face_toolbox_keras.models.parser import face_parser\n",
        "fp = face_parser.FaceParser()\n",
        "\n",
        "from face_toolbox_keras.models.detector import face_detector\n",
        "fd = face_detector.FaceAlignmentDetector()\n",
        "\n",
        "from face_toolbox_keras.models.detector.iris_detector import IrisDetector\n",
        "idet = IrisDetector()\n",
        "#idet.set_detector(fd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_3cxE0-Lfee"
      },
      "source": [
        "## Upload test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PoFePLoelz__"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from utils import utils\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJy8TIc3m0n_"
      },
      "outputs": [],
      "source": [
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oduY1uoSl0AI"
      },
      "outputs": [],
      "source": [
        "# Upload a source face image.\n",
        "# There should be only one source face image.\n",
        "fn_src = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAw05ir2l0AN"
      },
      "outputs": [],
      "source": [
        "# Upload target face images.\n",
        "# Number of target face images is not restricted as long as they belong to the same identity.\n",
        "fns_tar = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gvoYSeCoghg"
      },
      "outputs": [],
      "source": [
        "# Set input image path\n",
        "fn_src = [k for k,v in fn_src.items()]\n",
        "if len(fn_src) >= 1:\n",
        "    fn_src = fn_src[0]\n",
        "\n",
        "fns_tar = [k for k,v in fns_tar.items()]\n",
        "\n",
        "print(fn_src)\n",
        "print(fns_tar)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8tAH7KwLfef"
      },
      "outputs": [],
      "source": [
        "# We can also manually assign filenmes using the following code\n",
        "#fn_src = \"test02.jpg\"\n",
        "#fns_tar = [\"test01.jpg\", \"test03.jpg\", \"test04.jpg\", \"test05.jpg\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8rD90Ljlz_5"
      },
      "source": [
        "## Translate faces"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drpzzGCgl0AW"
      },
      "source": [
        "### Inferece\n",
        "\n",
        "It requires additional time to load models for the first infernce."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGaNnRHkl0AX"
      },
      "outputs": [],
      "source": [
        "src, mask, aligned_im, (x0, y0, x1, y1), landmarks = utils.get_src_inputs(fn_src, fd, fp, idet, identity_extractor=config[\"identity_extractor\"])\n",
        "tar, emb_tar = utils.get_tar_inputs(fns_tar, fd, fv, identity_extractor=config[\"identity_extractor\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qeleIZzwl0Ag"
      },
      "outputs": [],
      "source": [
        "out = model.inference(src, mask, tar, emb_tar)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqTEOcqxl0Ak"
      },
      "source": [
        "### Visualize results\n",
        "\n",
        "Images are resized to having maximum side length of 768."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8HqdLaD6Lfeg"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(src)\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(tar)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0P-d5H1Lfeg"
      },
      "outputs": [],
      "source": [
        "result_face = np.squeeze(((out[0] + 1) * 255 / 2).astype(np.uint8))\n",
        "plt.imshow(result_face)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44qXGZLkLfeg"
      },
      "outputs": [],
      "source": [
        "result_img = utils.post_process_result(fn_src, fd, result_face, aligned_im, src, x0, y0, x1, y1, landmarks)\n",
        "plt.imshow(result_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Do9x9wZl0BK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "test.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}